\documentclass[a4paper]{article}

\usepackage{amsmath,amssymb,amsfonts,thumbpdf,url}
\usepackage[utf8]{inputenc}
\usepackage{multirow,longtable}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{a4wide}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{Sweave}
\usepackage{natbib}
\usepackage{sfmath, amsmath}

%% additional commands
\newcommand{\squote}[1]{`{#1}'}
\newcommand{\dquote}[1]{``{#1}''}
\newcommand{\fct}[1]{{\texttt{#1()}\index{#1@\texttt{#1()}}}}
\newcommand{\class}[1]{\dquote{\texttt{#1}}}

%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{README} (#1)}}

%% jss stuff
\let\proglang=\textsf
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\bibliographystyle{jss}
\makeatletter
\newcommand\code{\bgroup\@makeother\_\@makeother\~\@makeother\$\@codex}
\def\@codex#1{{\normalfont\ttfamily\hyphenchar\font=-1 #1}\egroup}
\makeatother
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}

%% other settings
\SweaveOpts{engine = R, eps = FALSE, pdf = FALSE, png = TRUE, resolution = 120, keep.source = TRUE}
\setlength{\parindent}{0pt}
\setlength{\parskip}{4pt}

<<preliminaries, echo=FALSE, results=hide>>=
options(width = 70, prompt = "R> ", continue = "+  ", scipen = 2,
  SweaveHooks = list(fig = function() par(mar = c(4.1, 4.1, 0.1, 0.1))))
library("R2BayesX")
@

\renewcommand{\sfdefault}{phv}
\IfFileExists{sfmath.sty}{
  \RequirePackage{sfmath}
  \renewcommand{\rmdefault}{phv}
}{}

\pagestyle{empty}


\begin{document}
\SweaveOpts{concordance=TRUE}

\textbf{\Large Reviewer 1}

\begin{itemize}

\item \emph{Is there any option to run multiple chains within
  a single command call so that other convergence
  diagnostics such as the Gelman Rubin statistic can
  be computed? Related to this, would it be possible
  to distribute chains to different cores on a
  multiple-cores machine?}

  \medskip

  Yes, according to your recommendations we have now implemented multiple chain and core processing
  using the functionality of the \pkg{parallel} package. The user can now start models on e.g.,
  3~cores with 2~chains each:
<<eval=FALSE>>=
data("GAMart", package = "R2BayesX")
b <- bayesx(num ~ fac + sx(x1) + sx(x2) + sx(x3) +
  sx(long, lat, bs = "te") + sx(id, bs = "re"),
  data = GAMart, method = "MCMC", chains = 2, cores = 3)
@
  The object \code{b} is also of class \code{"bayesx"} for which all e.g., plotting and extractor
  functions can be applied. We have also adapted the \fct{samples} extractor function, which by
  default returns objects of class \code{"mcmc"} for a single chain or \code{"mcmc.list"} for
  multiple chains, as provided in the \pkg{coda} package. In addition, we have implemented a
  convenience function that directly computes the Gelman and Rubin convergence diagnostic using
  function \code{gelman.diag()} from the \pkg{coda} package. E.g.
<<eval=FALSE>>=
GRstats(b, term = "linear-samples")
GRstats(b, term = c("sx(x1)", "sx(long,lat)"), multivariate = TRUE)
@


\item \emph{The STEP method for model/variable selection is
  interesting, as demonstrated in Section 6.3. However,
  at the moment only the ``best" model is reported. Is
  it possible to compute the posterior model probability
  (cf.\ a summary output from the RJMCMC interface in
  WinBUGS, see Lunn et al. 2008, subsection 5.1)?
  (Lunn, D. J., Best, N. and Whittaker, J. (2008)
  Generic reversible jump MCMC using graphical models,
  Statistics and Computing)}

  \medskip

  The STEP method optimizes some goodness-of-fit criterion (e.g., AIC) using model optimization
  heuristics as described in
  
  Belitz C, Lang S (2008). ``Simultaneous Selection of Variables and Smoothing Parameters in
  Structured Additive Regression Models.'' \emph{Computational Statistics \& Data Analysis},
  \textbf{53}, 61--81.
  
  The algorithms are designed such that they provide good or near optimal models (in terms of the
  goodness of fit criterion) within a small number of iterations to minimize computing time. The 
  drawback of this procedure is that our search path contains only a few models such that
  posterior inclusion probabilities are generally not available. However, the bootstrap approach 
  for obtaining unconditional confidence bands also provides a frequency table of the relative
  frequency with which each model term has been selected during the bootstrap iterations. We have now
  implemented an extractor function \code{term.freqs()} to make these frequency tables easily
  available. We have also added a small example in Section~6.3 using the bootstrap option.


\item \emph{Not being able to store large objects is an issue
  in R. How does R2BayesX scale up to cope with outputs
  from large (e.g., spatio-temporal) models?}

  \medskip

  For the original data, the user can either store these in the usual way in \proglang{R}
  (with the usual limitations) or store them in a plain text file on the disk and pass them
  directly to \pkg{BayesX} (see Section~5.1). The model output files generated by \pkg{BayesX} are
  optimized (see Appendix~D) to alleviate the memory burden to some degree. For example,
  only predictions for unique covariate values are computed and read back into \proglang{R}.
  However, the model output for spatio-temporal data with a large number of time intervals could
  still be improved, since locations/coordinates will be replicated in the model output for every
  period prediction. So far, we did not experience any limitations/problems applying spatio-temporal
  models though.


\item \emph{Although missing data is implicitly discussed in the
  childhood malnutrition example, how are missing data
  generally coded in BayesX/R2BayesX? It is not immediately
  clear by looking at the data (ZambiaNutrition).}

  \medskip
  
  \pkg{R2BayesX} uses the standard approach via the \code{na.action} argument (see Section~5.1).
  Thus, using the standard default settings, \code{NA}s are simply omitted when
  the data are prepared in \proglang{R} for \pkg{BayesX}. But other approaches can
  be employed in the usual way. If \code{NAs} remain in the
  data sent over, \pkg{BayesX} will remove these.
 

\item \emph{How to compute posterior summary of transformed variables
  (e.g., posterior probability or prediction of outcome given
  covariates)?}
 
  \medskip

  User-defined summaries of parameters can be obtained by extracting samples with the extractor
  function \fct{samples}, which can then be used in combination with function such as \fct{quantile}
  etc. \pkg{BayesX} does not have functionality to compute predictions at the moment, however, as a
  workaround, we have now implemented a prediction method in \proglang{R} that is based on refitting
  the initial model with weights set to zero for new observations. The method can be used in the
  same fashion as other commonly used prediction methods, e.g., as provided for models of class
  \code{"lm"}, \code{"glm"}, and \code{"gam"}. In addition, the method can also return the full
  refitted model for which again all plotting and extractor functions can be used.


\item \emph{It would be useful to provide some guidance on specifying
  the degrees and knots when using p-spline in practice (do
  we perform a sensitivity analysis on different settings
  for knots/degrees? Also are the basis functions first
  pre-specified based on the fixed and equally spaced knots
  and are fixed throughout the MCMC run?)}

  \medskip

  The default settings have been thoroughly tested and should fit for common regression problems.
  The common user does usually not have to do sensitivity checks. We have added some more
  explanations in Section~5.2 (Available additive terms). Please find more information
  on Bayesian P-splines in:
  
  Lang S, Brezger A (2004). ``Bayesian P-Splines.'' \emph{Journal of Computational and Graphical
  Statistics}, \textbf{13}, 183--212.
  
  Brezger A, Lang S (2006). ``Generalized Structured Additive Regression Based on Bayesian
  P-Splines.'' \emph{Computational Statistics \& Data Analysis}, \textbf{50}, 947--991.
  
  The user may look up all default settings for all possible terms using function \linebreak
  \code{bayesx.term.options()}. All basis functions are only computed once and are then fixed for
  all iterations of the MCMC sampler and are not modified anymore.


\item \emph{Could the authors briefly compare BayesX to WinBUGS and INLA?
  Although it is not the main aim of this paper and perhaps
  can itself form another paper, this brief comparison can
  give readers a clearer idea of what these packages offer.}

  \medskip

  This is discussed in
  
  Brezger A, Kneib T, Lang S (2005). ``\pkg{BayesX}: Analyzing Bayesian Structured Additive
  Regression Models.'' \emph{Journal of Statistical Software}, \textbf{14}(11), 1--22. \\
  URL~\url{http://www.jstatsoft.org/v14/i11/.}
  
  In Section~3 of the paper a thorough comparison of software with built in functions for GAM modeling is presented
  and also a section with a \pkg{WinBUGS} comparison. We have added a small paragraph at the end of
  Section~3 (of the paper under review) that points out software packages which have a similar scope.


\item \emph{Sections 2 and 3 can be merged into one section, which first
  introduces the STAR models and then gives the motivating
  example. I think the R commands in the motivating example
  can be simplified (on the initial reading, I skipped most
  of the command lines).}

  \medskip

  We have removed the separate setup of the formula which saves one command line.
  The remaining commands are \code{data}, \code{bayesx}, \code{summary}, and three
  \code{plot}s. So there is not much room for simplification and we feel that
  all three plots are worthwhile and do not need too much space.
  
  As for the suggestion to merge Sections~2 and~3, we have decided
  to keep them separate to make it easier to access (or skip) the theory
  section.


\item \emph{On page 21, please rewrite the sentence ``The range of the
  estimated random spatial effect is much ...". Both Figures 4
  and 5 suggest the spatially structured random effect is
  more important than the unstructured one. The variance
  partition coefficient can be computed here to report
  the relative importance of each random effect component.}

  \medskip

  Yes, we could compute $\tau_1^2(\tau_1^2 + \tau_2^2)$, but these are two different variances,
  one of a Markov random field and the other of an i.i.d.\ random effect. As has been shown in
  
  Fahrmeir L, Lang S (2001). ``Bayesian Inference for Generalized Additive Mixed Models Based
  on Markov Random Field Priors.'' \emph{Journal of the Royal Statistical Society C}, \textbf{50},
  201--220.
  
  the unstructured and the structured spatial effect can generally not be separated and are often
  estimated with bias. Only the sum of both effects is estimated satisfactorily. This means in
  practice that only the complete spatial effect should be interpreted and nothing (or not much) can
  be said about the relative importance of both effects. Exceptions are cases where one of both
  effects (either the unstructured or the structured effect) is estimated to be practically zero and the
  other effect clearly dominates. Therefore, we usually do not put too much weight on this and
  prefer a graphical comparison. We have added these explanations in Section~6.1, too.


\item \emph{On page 22, autocorrelation is one measure for assessing
  convergence. However, chains trapped at some local modes
  can sometimes have ``well-behave'' ACF. Multiple chains should
  be run (see general comment 1 above).}

  \medskip

  We have now added an example using 2 chains where we compute the Gelman and Rubin convergence
  diagnostic for certain parameters.


\end{itemize}


\newpage


\textbf{\Large Reviewer 2}

\begin{itemize}

\item \emph{The installation of R2BayesX on OSX was problematic. It didn't
  install at all in R 2.14.  After a clean install of R (R version
  2.15.1 (2012-06-22), Platform: x86\_64-apple-darwin9.8.0/x86\_64 (64-bit)),
  the default installer still didn't work.  A google search for
  the error (dyld: Library not loaded: /usr/local/lib/libreadline.5.2.dylib),
  shows that this is a problem that others have had.}

  \medskip

  Thanks for pointing this out. We fixed this now:
  \verb|-L${R_HOME}/lib| is now included in the \verb|LDFLAGS| of the \verb|Makefile|
  which fixes readline linkage failure on OS~X.


\item \emph{I tried to run the munich rent example that comes with INLA in R2BayesX
  (\url{http://www.r-inla.org/examples/volume-1}) in order to get a grip on how
  easy R2BayesX was to use.
  I first tried to run it without the spatial effect, at which point I was
  informed that the variable names were not valid (they had .'s in them).
  This is quite tedious and should probably appear in the text.  It would
  be even better if the variables could be renamed internally to fix this
  problem automatically.
  Firstly, the graph file was in the wrong form, which was inconvenient.
  After checking with the BayesX manual, I wrote a short awk script to
  convert the inla graph format to the BayesX format \medskip \\
  $\phantom{mm}$\code{awk 'NF == 1 {print \$0};  NF > 2 {print \$1 - 1; print \$2; \$1="";} \\
  $\phantom{mm}$\code{\$2 = ""; for (i=3;i<=NF;i++){\$i = \$i-1}; print \$0}' < munich.graph >} \\
  $\phantom{mm}$\code{munich.bayesx.graph} \medskip \\
  It would be convenient if the authors to provide some mechanisms to
  construct graph files, rather than assuming that the graph file has
  been converted to the BayesX format.  Minimal functionality would be to
  extend read.gra() to take an adjacency matrix.  It's only half a dozen
  lines of code, but it's nice for users.}

  \medskip

  The naming problem for smooth terms has been fixed, names are checked and renamed internally.
  We have adapted the function \code{read.gra()}, it now fully supports both formats, the one
  suggested in the \pkg{BayesX} reference manual and the format of the \pkg{INLA} project. The
  manual page of \code{read.gra()} now includes a detailed description for setting up graph files,
  too. The Munich rent example code runs smoothly now
<<eval=FALSE>>=
url <- "http://www.math.ntnu.no/~hrue/r-inla.org/examples/munich/"
Munich <- read.table(file.path(url, "Munich.txt"), header = TRUE)
MunichGra <- read.gra(file.path(url, "munich.graph"))

f <- rent ~ sx(location, bs = "mrf", map = MunichGra) +
  sx(year) + sx(floor.size) + Gute.Wohnlage + Beste.Wohnlage +
  Keine.Wwv + Keine.Zh + Kein.Badkach  + Besond.Bad + Gehobene.Kueche +
  zim1 + zim2 + zim3 + zim4 + zim5 + zim6

b <- bayesx(f, data = Munich, seed = 1234)
summary(b)
@
\begin{Schunk}
\begin{Soutput}
Call:
bayesx(formula = f, data = Munich, seed = 1234)
 
Fixed effects estimation results:

Parametric Coefficients:
                   Mean      Sd    2.5%     50%   97.5%
(Intercept)      7.4400  2.2964  3.9236  7.2843 11.7855
Gute.Wohnlage    0.6170  0.1136  0.3948  0.6209  0.8217
Beste.Wohnlage   1.8010  0.3102  1.1676  1.8048  2.4069
Keine.Wwv       -1.9280  0.2734 -2.4586 -1.9300 -1.3780
Keine.Zh        -1.3779  0.1905 -1.7623 -1.3752 -0.9969
Kein.Badkach    -0.5600  0.1157 -0.7907 -0.5624 -0.3220
Besond.Bad       0.5136  0.1583  0.2009  0.5121  0.8184
Gehobene.Kueche  1.1352  0.1774  0.7855  1.1397  1.4779
zim1             0.2050  2.3148 -4.1562  0.4264  3.7749
zim2             0.5827  2.2971 -3.6820  0.7537  4.1176
zim3             0.4503  2.2936 -3.7556  0.6297  3.9758
zim4             0.0714  2.2929 -4.1738  0.2050  3.6210
zim5             0.3227  2.3296 -3.9760  0.5194  4.0501
zim6             0.2940  2.3754 -4.2415  0.4391  4.1771

Smooth terms variances:
                 Mean     Sd   2.5%    50%  97.5%    Min    Max
sx(floor.size) 0.4101 0.3332 0.0814 0.3086 1.3265 0.0535 2.4858
sx(location)   0.4997 0.1601 0.2378 0.4821 0.8578 0.1204 1.2812
sx(year)       0.0778 0.0785 0.0101 0.0551 0.2803 0.0022 0.7267
 
Scale estimate:
         Mean     Sd   2.5%    50%  97.5%
Sigma2 3.6640 0.1270 3.4208 3.6600 3.9208
 
N = 2035  burnin = 2000  DIC = 2134.859  pd = 96.26702  
method = MCMC  family = gaussian  iterations = 12000  step = 10
\end{Soutput}
\end{Schunk}


\item \emph{Would it be better in the STEP algorithm to set the quantiles to NA
  (not available) rather than 0.00?}

  \medskip

  Yes, thanks, we have set these to \code{NA} now.


\item \emph{In the bayesx() call, the family parameter is case sensitive (I
  accidentally wrote \code{"Gaussian"} instead of \code{"gaussian"}). This could be
  fixed with \code{tolower()}. A similar thing happened with \code{CI = "MCMCselect"}.}

  \medskip

  The case sensitivity for the \code{family} and \code{CI} parameter has been removed.


\item \emph{Section 2: The option \code{full = TRUE} in the formula is not
  mentioned anywhere else in this paper.  What does it do?}

  \medskip

  The option was accidently set and has been removed from the paper, it specifies the number of
  locations that should be used as knots. All options for all possible terms may be looked up using
  function \code{bayesx.term.options()} (Section~5.2).
<<opt1, echo=TRUE, eval=FALSE>>=
bayesx.term.options(bs = "gk", method = "REML")
@
<<opt2, echo=FALSE, eval=TRUE>>=
opt <- capture.output(bayesx.term.options(bs = "gk", method = "REML"))
writeLines(c(opt[1:6], "      [...]", opt[11:15], "      [...]"))
@


\item \emph{Section 3: Is the list on page 5 an exhaustive list of models
  implemented in R2BayesX?}

  \medskip

  No, these are just examples of model terms that fit in the STAR framework. There is more, e.g.,
  Bayesian ridge, Bayesian lasso, Kriging, etc.


\item \emph{Section 4.2: I note in passing that the INLA package can solve a
  large class of latent Gaussian models in which each observation depends
  linearly on the latent Gaussian field.  This includes GLMMs, GAMMs and
  many STAR (but not all -- variable coefficient models aren't implemented)
  models, as well as models where the link is not through the mean (such
  as stochastic volatility models).}

  \medskip

  We have now added a brief discussion at the end of Section~3 that points out
  software packages that have a similar scope (including \pkg{INLA}).


\item \emph{Table 4:  It would be useful to specify which GMRF model is being used.
  There are more than one! A reference would be sufficient.  Similar comment
  or ``geokriging" - which stationary GRF?}

  \medskip

  We have added a reference to the following paper in Table~4.
  
  Fahrmeir L, Kneib T, Lang S (2004). ``Penalized Structured Additive Regression for Space
  Time Data: A Bayesian Perspective.'' \emph{Statistica Sinica}, \textbf{14}, 731--761.
  
  This provides a detailed discussion of the methodology used.


\item \emph{Page 16 paragraph 2: What is a ``very large dataset" for BayesX? Are
  there benchmarks?}

  \medskip

  \pkg{BayesX} is able to handle rather complex models with several hundred thousand
  observations. E.g., we have successfully fitted a large model using precipitation data with more
  than a million observations. See also
  
  Umlauf N, Mayr G, Messner J, Zeileis A (2012). ``Why Does It Always Rain on Me? A
  Spatio-Temporal Analysis of Precipitation in Austria.'' \emph{Austrian Journal of Statistics},
  \textbf{41}(1), 81--92.


\item \emph{Page 20: I'm not a fan of an enormous piece of \proglang{R} output breaking
  a sentence.}

  \medskip

  Fixed.


\item \emph{Figure 4: I am unsure what the x axis on these images stand for.  And
  what exactly is the is kernel density estimate of? Is it just the density
  of the posterior ignoring the spatial location (i.e., lumping all of the
  distributions together)?  If so is there any statistical justification
  or meaning for this plot?  The locations are not independent!}

  \medskip

  The kernel density estimates are based on the posterior means of the sampled coefficients, i.e.,
  the estimated posterior mean coefficients for all regions are used. We have added some more
  explanation in the caption of Figure~4.


\item \emph{It would be nice to mention that all of these plotting options can be
  found in Appendix B.}

  \medskip

  Another pointer has been added after the code for Figure~4.


\item \emph{Bottom of page 22: probably didn't mean ``ore"...}

  \medskip

  Fixed.


\item \emph{Same place: As this is a manual, it would be nice to give some
  indication of the thought process behind increasing the number of
  iterations to 20k or 30k.}

  \medskip

  The number of iterations are chosen such that the samples after thinning are (nearly)
  uncorrelated. Hence the number of iterations depend primarily on the mixing behavior of the
  samples. The mixing behavior depends primarily on the complexity of the model and the amount of
  correlations among different model terms. We have added more information now.


\item \emph{Bottom of page 23: Most users would probably attack the 'verbose' option
  directly through the bayesx() call.  I note that it's mentioned earlier
  that the ellipsis argument in bayesx() maps to bayesx.control(), so this
  is implied by the current text, but it would probably be good to clarify.}

  \medskip
  
  We have added an additional note and a reference to Section~5 for better explanation.


\item \emph{Example in 6.2: Is there an easy way to perform spatial prediction
  with R2BayesX?  It would be nice to get a smooth spatial interpolant
  for the whole region.}

  \medskip

  Using function \code{plotmap()}, we have added an option to plot interpolated maps now, see
  Figure~10.


\end{itemize}


\newpage


\textbf{\Large Reviewer 3}

\begin{itemize}

\item \emph{Would it be possible to store all the masses of output information from
  BayesX in the fitted model object, for later retrieval, rather than printing
  it all to the screen? The current behaviour is really a bit off putting and
  not in the spirit of R modelling functions. (Warnings or errors are
  different of course, and should be printed out by default). Perhaps a
  verbose option could be used to turn printing back on, if needed?}

  \medskip

  We have a \code{verbose} option to suppress the output of the \pkg{BayesX} binary. Also, we check
  for possible errors in the log file of \pkg{BayesX}. We have set the default to
  \code{verbose = FALSE} now.


\item \emph{There seems to be an ordering problem with fitted.bayesx. I noticed this
  from a more complicated example, but actually the first example in ?bayesx
  illustrates the issue}

  \medskip

  Thanks for spotting this. The ordering problem has been fixed now.

\end{itemize}


\newpage


\textbf{\Large Reviewer 4}

\begin{itemize}

\item \emph{It is not entirely clear who the authors have in mind as the audience for the paper.
  The introduction emphasizes the relationship between BayesX and R2BayesX. The paper then has a
  nice motivating example, which unfortunately plays virtually no role until the very end of the 
  paper. In between, there is a section providing details on how the BayesX package was modified 
  into an R framework, followed by a long section that provides useful lists of the major options 
  used in the package. Finally, there is a nice section on estimating STAR models in practice.
  The discussion of the relationship between the two packages is probably useful to 
  someone who is familiar with BayesX. However, I would guess that the main audience for the paper 
  will be R users. As an R user who is now convinced that R2BayesX is extremely useful, I found 
  sections 2--5 to be frustrating and at time nearly useless. Though the package is incredibly 
  powerful and has many options, it is not until page 17 that we begin to learn how to use the 
  package in any detail.}

  \medskip

  It is true that there is some tension between the different objectives that the manuscript
  tries to accomplish. There are at least three groups of readers that we try to serve:
  (1)~\proglang{R}~users that do not know \pkg{BayesX} yet (who may or may not be aware of
  the unifying STAR framework), (2)~\pkg{BayesX} users who want to integrate their analyses
  with \proglang{R} (and may have more or less experience with other \proglang{R}~packages like
  \pkg{mgcv}), (3)~\proglang{R}~programmers interested in designing interfaces to external programs
  for fitting regression models.  
  We agree that (1) is likely to include the largest group of readers but we also want to
  provide sufficient information for (2) and~(3). 
  
\item \emph{Although it would involve substantial rewriting, I think the paper would be much more 
  useful if it were organized around the empirical examples. Section 4 could be placed in an 
  appendix. Though the most important parts of section 5 are the tables, the various options are
  not illustrated in any detail. It would be useful to organize the empirical applications around 
  these tables. Start with the base model. How do we implement the pspline options, kriging, 
  geokriging, and other options listed in Table 4? How do we access various results, which are 
  listed in Table 3. Finally, there might be some discussion of the usefulness of altering some of 
  the options listed in Table 2.}

  \medskip

  Many publications in \emph{Journal of Statistical Software} employ the sequence (1)~methods,
  (2)~implementation, (3)~application for introducing software packages. Hence, we also follow
  this setup. However, we now try to make this structure more obvious at the end of the introduction
  and verbosely encourage readers to skip forward if they are more interested in certain aspects
  of the manuscript.
  
  To improve the reading flow, we have now moved Section~5.3 to the appendix,
  since this section is probably less frequently used in practice.
  
\item \emph{In its current form, the reader is simply provided with a list of options in Table 
  2--4. In my view, these tables and the empirical examples are the crux of the paper. I was able 
  to use these tables to experiment successfully with some of my own data sets. I was very 
  impressed. My complaint is that I did most of this work on my own with reference to Tables 2--4. 
  I found it somewhat difficult to figure out how to access some of the results when I wanted to 
  produce my own graphs. I also found the difference between options such as pspline, kriging, 
  geokriging, and geospline to be confusing. It would be straightforward to modify the empirical 
  examples to illustrate some of these differences and to show how to access the model results.}

  \medskip

  The STAR model framework is a quite complex issue, we have the feeling that a detailed
  description is beyond the scope of the paper. In fact, the focus of the current paper is to
  describe the interface between the \proglang{R} computing environment and \pkg{BayesX} via the
  package \pkg{R2BayesX} and not to describe STAR models and methods in detail. The latter has been
  done (to some extent) in a previous paper in JSS on \pkg{BayesX}

  Brezger A, Kneib T, Lang S (2005). ``\pkg{BayesX}: Analyzing Bayesian Structured Additive
  Regression Models.'' \emph{Journal of Statistical Software}, \textbf{14}(11), 1--22. \\
  URL~\url{http://www.jstatsoft.org/v14/i11/.}

  and more details are available in

  Fahrmeir L, Kneib T, Lang S, Marx B (2013). ``Regression -- Models, Methods and Applications.''
  \emph{Springer-Verlag}, Berlin. ISBN 978-3-642-34332-2.

  and also in the \pkg{BayesX} methodological references. Adding all detail again would lead to a
  very long manuscript that would also change the main subject considerably

\item \emph{It might also be useful if the authors added a brief discussion of some of the
  advantages of STAR models over other approaches. They mention alternatives such as GAM, GAMM, 
  and varying coefficient models, and point out that each of these can be considered a special 
  case of the STAR approach. Again, this might serve as a useful organizing principle for the 
  empirical examples. Suppose we want to estimate a GAM model; how is it accomplished using the
  Bayes2X package?}

  \medskip

  As desbribed in Section~3, the STAR model approach, which comprises several models such as GAM,
  GAMM, VCM etc.\ proposes an unified treatment of the model components. Sure, the transition of
  e.g.\ GAM to STAR is smooth. However, since we adopt the Bayesian perspective this has the
  advantage, that all model term priors can be represented in a general form, which is heavily
  utilized in \pkg{BayesX} by unified estimation procedures. In

  Fahrmeir L, Kneib T, Lang S (2004). ``Penalized Structured Additive Regression for Space
  Time Data: A Bayesian Perspective.'' \emph{Statistica Sinica}, \textbf{14}, 731--761.

  special cases of STAR models are discussed in more detail. We have added this reference also in
  Section~3.

\end{itemize}


\end{document}

